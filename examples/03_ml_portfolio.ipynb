{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40ddca27-d79d-46cc-b805-232e0515b6aa",
   "metadata": {},
   "source": [
    "# Example Notebook #3 - ML Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcbfafca-c560-47a1-8505-7db8b0918453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import talib\n",
    "import seaborn as sns\n",
    "from portfolio_swissknife import portfolio as ps\n",
    "from portfolio_swissknife import models as mod\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39560f9b-024e-49cc-95ff-33752fee3508",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "opn = pd.read_csv('../ext_data/00_db_SPX__PX_OPEN.csv',index_col=0, parse_dates=True)\n",
    "opn.columns = opn.columns.map(lambda x:x.split(' ')[0])\n",
    "opn = opn[::-1]\n",
    "opn = opn.loc[:,~opn.columns.duplicated()]\n",
    "\n",
    "high = pd.read_csv('../ext_data/00_db_SPX__PX_HIGH.csv',index_col=0, parse_dates=True)\n",
    "high.columns = high.columns.map(lambda x:x.split(' ')[0])\n",
    "high = high[::-1]\n",
    "high = high.loc[:,~high.columns.duplicated()]\n",
    "\n",
    "low = pd.read_csv('../ext_data/00_db_SPX__PX_LOW.csv',index_col=0, parse_dates=True)\n",
    "low.columns = low.columns.map(lambda x:x.split(' ')[0])\n",
    "low = low[::-1]\n",
    "low = low.loc[:,~low.columns.duplicated()]\n",
    "\n",
    "\n",
    "close = pd.read_csv('../ext_data/00_db_SPX__PX_LAST.csv',index_col=0, parse_dates=True)\n",
    "close.columns = close.columns.map(lambda x:x.split(' ')[0])\n",
    "close = close[::-1] #ascending dates\n",
    "close = close.loc[:,~close.columns.duplicated()]\n",
    "\n",
    "volume = pd.read_csv('../ext_data/00_db_SPX__PX_VOLUME.csv',index_col=0, parse_dates=True)\n",
    "volume.columns = volume.columns.map(lambda x:x.split(' ')[0])\n",
    "volume = volume[::-1]\n",
    "volume = volume.loc[:,~volume.columns.duplicated()]\n",
    "\n",
    "\n",
    "macro = pd.read_excel('../ext_data/macro.xlsx',sheet_name = 'data', index_col = 0, parse_dates = True)\n",
    "# macro.index = macro.index.to_period('M')\n",
    "\n",
    "with open('../ext_data/features.pkl', 'rb') as handle:\n",
    "    fund = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6ad0907-bab5-47f2-a36a-723f58d9872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test case\n",
    "tc = pd.DataFrame(close['MSFT'])\n",
    "to = opn['AAPL']\n",
    "tl = low['AAPL']\n",
    "th = high['AAPL']\n",
    "tv = volume['AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce8a8a3f-a4a1-430c-b4e8-e0a6e6e6503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tc['SMA200'] = talib.SMA(tc['AAPL'], timeperiod = 200)\n",
    "# tc['SMA50'] = talib.SMA(tc['AAPL'], timeperiod = 50)\n",
    "# tc['MOM3M'] = talib.MOM(tc['AAPL'], timeperiod = 63)\n",
    "# tc['RSI14d'] = talib.RSI(tc['AAPL'])\n",
    "# tc['ADX14'] = talib.ADX(th, tl, tc['AAPL'])\n",
    "# tc['ATR14'] = talib.ATR(th, tl, tc['AAPL'])\n",
    "# # tc['CDL3OUT'] = talib.CDL3OUTSIDE(to,th,tl,tc['AAPL'])\n",
    "# tc['DCPERIOD'] = talib.HT_DCPERIOD(tc['AAPL'])\n",
    "# # tc['WILLR'] = talib.WILLR(th, tl, tc['AAPL'])\n",
    "# _, tc['MACD'], _ = talib.MACD(tc['AAPL'])\n",
    "# tc['BBANDUP'], tc['BBANDMID'], tc['BBANDDOWN'] = talib.BBANDS(tc['AAPL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cc28d8f-b9ab-4322-8011-212366093610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tc = tc.fillna(method = 'ffill').loc[tc.notna().all(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f17824b3-29a8-4872-8b2c-e70da933dd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro = macro.loc[tc.index[0]:tc.index[-1]] #reindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70bf7f51-a790-435a-9623-36daa16374b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "class DataHandler:\n",
    "    #Rewrite so that it can be applicable at __init__ of more complex portfolios\n",
    "    def __init__(self, func):\n",
    "        functools.update_wrapper(self, func)\n",
    "        self.func = func\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        #identify args\n",
    "        args = list(args)\n",
    "        for arg in args:\n",
    "            if isinstance(arg, pd.Series) or isinstance(arg, pd.DataFrame):\n",
    "                if arg.shape[0] == 1 or arg.shape[1] == 1:\n",
    "                    y_old = arg\n",
    "                else:\n",
    "                    x_old = arg\n",
    "                    \n",
    "        #merge and align data\n",
    "        m1 = pd.merge(y_old, x_old, left_on = y_old.index,\n",
    "                                    right_on = x_old.index,\n",
    "                                    how = 'right')\n",
    "        m1.index = m1['key_0']\n",
    "        m1 = m1.drop('key_0',axis=1)\n",
    "        m1 = m1.fillna(method='ffill').dropna()\n",
    "        \n",
    "        \n",
    "        y_new = m1.iloc[:,0]\n",
    "        x_new = m1.iloc[:,1:]\n",
    "        new_args = {'y': y_new,\n",
    "                    'X': x_new}\n",
    "        \n",
    "        self.func(**new_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7258876-f025-4fb7-b6cd-3a404e3e5bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @DataHandler\n",
    "# def test(y,X):\n",
    "#     mod = LinearRegression().fit(X = X, y = y)\n",
    "#     print(mod.coef_)\n",
    "# test(tc, macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33c28357-6f25-41cf-b483-d6764e72b3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#monthly data\n",
    "\n",
    "merge1 = pd.merge(close, macro, left_on = tc.index,\n",
    "                    right_on = macro.index,\n",
    "                    how = 'right')\n",
    "merge1.index = merge1['key_0']\n",
    "merge1 = merge1.drop('key_0',axis=1)\n",
    "merge1 = merge1.fillna(method='ffill').to_period('M')\n",
    "fundm = fund['AAPL'].to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d54b6ef-39b6-42fd-9756-4d62708a4083",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge2 = pd.merge(merge1, fundm, left_on = merge1.index,\n",
    "                               right_on = fundm.index,\n",
    "                               how = 'left')\n",
    "merge2.index = merge2['key_0']\n",
    "merge2 = merge2.drop('key_0',axis=1)\n",
    "merge2 = merge2.fillna(method = 'bfill').fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "298c67e6-b398-4f12-ac24-ae63b9d14723",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = merge2['ABMD']\n",
    "#simple label threshold\n",
    "y = y.diff().apply(lambda x: 1 if x >= 0.02 else 0).shift(-1).dropna()\n",
    "# stdev bound label\n",
    "\n",
    "X = merge2.iloc[:-1,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "249e6fa1-473f-4368-b39e-cc3521cb932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#daily data\n",
    "# merge1 = pd.merge(tc, fund['AAPL'], left_on = tc.index, \n",
    "#                   right_on = fund['AAPL'].index, \n",
    "#                   how = 'left')\n",
    "# merge1.index = merge1['key_0']\n",
    "# merge1 = merge1.drop('key_0',axis=1)\n",
    "# merge1 = merge1.fillna(method = 'bfill').fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d20693fc-402b-4a27-bcc4-85f26311f639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge2 = pd.merge(merge1, macro, left_on = merge1.index,\n",
    "#                   right_on = macro.index,\n",
    "#                   how = 'left')\n",
    "# merge2.index = merge2['key_0']\n",
    "# merge2 = merge2.drop('key_0',axis=1)\n",
    "# merge2 = merge2.fillna(method = 'bfill').fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63ce8141-b66d-4f77-bdeb-fb786f611195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #simple label threshold\n",
    "# y = y.diff().apply(lambda x: 1 if x >= 0 else 0).shift(-1).dropna()\n",
    "# #stdev bound label\n",
    "\n",
    "# X = merge2.iloc[:-1,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de08b015-0c97-40a1-a5e4-fae4f1cf5e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_training_episode(y, X):\n",
    "    #labeling\n",
    "    y = y.apply(lambda x: 1 if x >= 0.02 else 0)\n",
    "    \n",
    "    #grid search\n",
    "    grid = {'n_estimators': [200, 500], 'max_depth': [3, 9, 12],\n",
    "            'max_features': [4, 8, 12], 'random_state': [42]}\n",
    "    test_scores = []\n",
    "\n",
    "    rf_model = RandomForestClassifier()\n",
    "\n",
    "    for g in ParameterGrid(grid):\n",
    "        rf_model.set_params(**g) \n",
    "        rf_model.fit(X, y)\n",
    "        test_scores.append(rf_model.score(X, y))\n",
    "\n",
    "    best_index = np.argmax(test_scores)\n",
    "    \n",
    "    #fitting the optimal model\n",
    "    rf = RandomForestClassifier(**ParameterGrid(grid)[best_index])\n",
    "    rf.fit(X, y)\n",
    "    \n",
    "    pred_prob_long = rf.predict_proba(X)[-1][1]\n",
    "    return pred_prob_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78351008-2520-4d17-8af9-d4c9ce1183b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading ext. data -- close prices of SPX\n",
    "universe = pd.read_csv('../ext_data/00_db_SPX__PX_LAST.csv', index_col = 0, parse_dates = True)\n",
    "universe = universe[::-1].loc[:,universe.notna().all(axis=0)]\n",
    "securities = [universe.columns[i].split(' ')[0] for i, _ in enumerate(universe.columns)]\n",
    "universe.columns = securities\n",
    "missing = ['BF/B','BRK/B','CXO','ETN','LB','VAR','UAL']\n",
    "universe = universe.drop(missing, axis = 1)\n",
    "securities = [elem for elem in securities if elem not in missing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b7494a6e-bf76-48db-8e82-cc4b00b58e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "port_universe = ps.Portfolio(securities[357:])\n",
    "port_universe.set_custom_prices(universe, 'daily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "25b660d6-a2c4-41fe-b692-0ffc6ed8b8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model = mod.PredictionModel(port_universe)\n",
    "pred_model.set_features(macro.to_period('M')) #add macro features\n",
    "pred_model.set_features({sec : fund[sec].to_period('M') for \n",
    "                         sec in fund.keys()}) #add fundamental features\n",
    "pred_model.prepare_targets(macro)\n",
    "pred_model.set_prediction_model(rf_training_episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "52f59988-a423-4659-9838-8cee67c5a2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb4fb65384540ad869c0f9248172140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training ML models:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_model.rolling_model_prediction(estimation_period=60, window = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f618f181-93b2-4ec7-aaf9-2f504a49ca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save intermediate results\n",
    "with open('tree_preds_2.pkl', 'wb') as handle:\n",
    "    pickle.dump(pred_model.prediction_measure, handle, protocol= pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "55f7331a-e118-4969-8174-338b338f918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tree_preds_1.pkl', 'rb') as handle:\n",
    "    preds_1 = pickle.load(handle)\n",
    "with open('tree_preds_2.pkl', 'rb') as handle:\n",
    "    preds_2 = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a191b1b7-8059-4571-8ee9-351278c46e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_all = {**preds_1, **preds_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33976563-d106-4c90-81ac-ccfc14ef5266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
